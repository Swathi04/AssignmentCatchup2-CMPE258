{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AssignmentCatchup2Partb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXgk5nLNnFpfGnEm5wyW1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swathi04/AssignmentCatchup2-CMPE258/blob/main/AssignmentCatchup2Partb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8WeEpdX4Vx2"
      },
      "source": [
        "#Edge Prediction Problem using GCN and GAT layers\n",
        "\n",
        "**Submitted By: Swathi Anandram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUxD4gOd-AuO"
      },
      "source": [
        "## Setup: Install and Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OyH_VgjW7Bp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1154329-33c7-4903-b55c-f1d56d3672a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/deepmind/jraph.git\n",
            "  Cloning https://github.com/deepmind/jraph.git to /tmp/pip-req-build-687kcp89\n",
            "  Running command git clone -q https://github.com/deepmind/jraph.git /tmp/pip-req-build-687kcp89\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from jraph==0.0.2.dev0) (0.3.8)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from jraph==0.0.2.dev0) (0.3.7+cuda11.cudnn805)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from jraph==0.0.2.dev0) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->jraph==0.0.2.dev0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->jraph==0.0.2.dev0) (4.2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->jraph==0.0.2.dev0) (1.0.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->jraph==0.0.2.dev0) (1.4.1)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->jraph==0.0.2.dev0) (2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax>=0.1.55->jraph==0.0.2.dev0) (1.15.0)\n",
            "Building wheels for collected packages: jraph\n",
            "  Building wheel for jraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jraph: filename=jraph-0.0.2.dev0-py3-none-any.whl size=85756 sha256=bc2cab975e05c633dfa7fcb21a1c4c9164519429f2b06416eafa5b2afdf19545\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-is1d0kpy/wheels/89/dc/20/0a1de4506ab4513ae6ceb33168677609670d891520b45470e0\n",
            "Successfully built jraph\n",
            "Installing collected packages: jraph\n",
            "Successfully installed jraph-0.0.2.dev0\n",
            "Collecting flax\n",
            "  Downloading flax-0.4.2-py3-none-any.whl (186 kB)\n",
            "\u001b[K     |████████████████████████████████| 186 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from flax) (4.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.21.6)\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.2-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax>=0.3 in /usr/local/lib/python3.7/dist-packages (from flax) (0.3.8)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (1.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax>=0.3->flax) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.3-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 266 kB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.3.7+cuda11.cudnn805)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.1.7)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.11.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax->flax) (2.0)\n",
            "Installing collected packages: chex, optax, flax\n",
            "Successfully installed chex-0.1.3 flax-0.4.2 optax-0.1.2\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.6-py3-none-any.whl (309 kB)\n",
            "\u001b[K     |████████████████████████████████| 309 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.0.0)\n",
            "Collecting jmp>=0.0.2\n",
            "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (4.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->dm-haiku) (1.15.0)\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.6 jmp-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/deepmind/jraph.git\n",
        "!pip install flax\n",
        "!pip install dm-haiku"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RJm7y6GH3WyB"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "%matplotlib inline\n",
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.tree_util as tree\n",
        "import jraph\n",
        "import flax\n",
        "import haiku as hk\n",
        "import optax\n",
        "import pickle\n",
        "import numpy as onp\n",
        "import networkx as nx\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C5YI9M0vwvb"
      },
      "source": [
        "##Introduction to jraph library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wK0rGWf56-Uq"
      },
      "outputs": [],
      "source": [
        "def build_toy_graph() -> jraph.GraphsTuple:\n",
        "  \"\"\"Define a four node graph, each node has a scalar as its feature.\"\"\"\n",
        "\n",
        "  # Nodes are defined implicitly by their features.\n",
        "  # We will add four nodes, each with a feature, e.g.\n",
        "  # node 0 has feature [0.],\n",
        "  # node 1 has featre [2.] etc.\n",
        "  # len(node_features) is the number of nodes.\n",
        "  node_features = jnp.array([[0.], [2.], [4.], [6.]])\n",
        "\n",
        "  # We will now specify 5 directed edges connecting the nodes we defined above.\n",
        "  # We define this with `senders` (source node indices) and `receivers`\n",
        "  # (destination node indices).\n",
        "  # For example, to add an edge from node 0 to node 1, we append 0 to senders,\n",
        "  # and 1 to receivers.\n",
        "  # We can do the same for all 5 edges:\n",
        "  # 0 -> 1\n",
        "  # 1 -> 2\n",
        "  # 2 -> 0\n",
        "  # 3 -> 0\n",
        "  # 0 -> 3\n",
        "  senders = jnp.array([0, 1, 2, 3, 0])\n",
        "  receivers = jnp.array([1, 2, 0, 0, 3])\n",
        "\n",
        "  # You can optionally add edge attributes to the 5 edges.\n",
        "  edges = jnp.array([[5.], [6.], [7.], [8.], [8.]])\n",
        "\n",
        "  # We then save the number of nodes and the number of edges.\n",
        "  # This information is used to make running GNNs over multiple graphs\n",
        "  # in a GraphsTuple possible.\n",
        "  n_node = jnp.array([4])\n",
        "  n_edge = jnp.array([5])\n",
        "\n",
        "  # Optionally you can add `global` information, such as a graph label.\n",
        "  global_context = jnp.array([[1]]) # Same feature dims as nodes and edges.\n",
        "  graph = jraph.GraphsTuple(\n",
        "      nodes=node_features,\n",
        "      edges=edges,\n",
        "      senders=senders,\n",
        "      receivers=receivers,\n",
        "      n_node=n_node,\n",
        "      n_edge=n_edge,\n",
        "      globals=global_context\n",
        "      )\n",
        "  return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "82Jtg_y-TqCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c7d52d-15bc-4ce4-f8bc-985d3ce12af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "graph = build_toy_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnWGPulK_tYE"
      },
      "source": [
        "#### Inspecting the GraphsTuple\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jjfUYT_UzoQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b1c63b-bfcf-4614-c962-c48f6d9352a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([4], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "graph.n_node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BQLF-mfOzXGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6908461-91a4-4268-8331-0a83406d189d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([5], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Number of edges\n",
        "graph.n_edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gdzVSy04zp3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c693e600-0971-4e6e-d362-7a25ab365578"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[0.],\n",
              "             [2.],\n",
              "             [4.],\n",
              "             [6.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Node features\n",
        "graph.nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P9_VpQSZzua3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794f2929-a50e-4a95-c00c-b993966ac8c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[5.],\n",
              "             [6.],\n",
              "             [7.],\n",
              "             [8.],\n",
              "             [8.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Edge features\n",
        "graph.edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pvN0pbg0z8Ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5febc5-78cf-43a8-b5f4-cca8bd4e5cb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([0, 1, 2, 3, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Edges\n",
        "graph.senders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aNI4PVR-z-HL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c143a4a-716c-480c-dab0-78e1df3cfabe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([1, 2, 0, 0, 3], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "graph.receivers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ayThRCYpz4wj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca40144-2104-4282-d8f7-a3206da40562"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Graph-level features\n",
        "graph.globals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3Pwh9e7d8gN"
      },
      "source": [
        "## Visualizing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e7q5ySSmVL3x"
      },
      "outputs": [],
      "source": [
        "def convert_jraph_to_networkx_graph(jraph_graph: jraph.GraphsTuple) -> nx.Graph:\n",
        "  nodes, edges, receivers, senders, _, _, _ = jraph_graph\n",
        "  nx_graph = nx.DiGraph()\n",
        "  if nodes is None:\n",
        "    for n in range(jraph_graph.n_node[0]):\n",
        "      nx_graph.add_node(n)\n",
        "  else:\n",
        "    for n in range(jraph_graph.n_node[0]):\n",
        "      nx_graph.add_node(n, node_feature=nodes[n])\n",
        "  if edges is None:\n",
        "    for e in range(jraph_graph.n_edge[0]):\n",
        "      nx_graph.add_edge(int(senders[e]), int(receivers[e]))\n",
        "  else:\n",
        "    for e in range(jraph_graph.n_edge[0]):\n",
        "      nx_graph.add_edge(\n",
        "          int(senders[e]), int(receivers[e]), edge_feature=edges[e])\n",
        "  return nx_graph\n",
        "\n",
        "\n",
        "def draw_jraph_graph_structure(jraph_graph: jraph.GraphsTuple) -> None:\n",
        "  nx_graph = convert_jraph_to_networkx_graph(jraph_graph)\n",
        "  pos = nx.spring_layout(nx_graph)\n",
        "  nx.draw(\n",
        "      nx_graph, pos=pos, with_labels=True, node_size=500, font_color='yellow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PNK5SeajWQWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "60e82518-fa21-4157-8591-76ba66bc6904"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "draw_jraph_graph_structure(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc6fCm0zzOv-"
      },
      "source": [
        "### Simple GCN Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Rc7u-eHvg5Zp"
      },
      "outputs": [],
      "source": [
        "def apply_simplified_gcn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "  # Unpack GraphsTuple\n",
        "  nodes, _, receivers, senders, _, _, _ = graph\n",
        "\n",
        "  # 1. Update node features\n",
        "  # For simplicity, we will first use an identify function here, and replace it\n",
        "  # with a trainable MLP block later.\n",
        "  update_node_fn = lambda nodes: nodes\n",
        "  nodes = update_node_fn(nodes)\n",
        "\n",
        "  # 2. Aggregate node features over nodes in neighborhood\n",
        "  # Equivalent to jnp.sum(n_node), but jittable\n",
        "  total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
        "  aggregate_nodes_fn = jax.ops.segment_sum\n",
        "\n",
        "  # Compute new node features by aggregating messages from neighboring nodes\n",
        "  nodes = tree.tree_map(lambda x: aggregate_nodes_fn(x[senders], receivers,\n",
        "                                        total_num_nodes), nodes)\n",
        "  out_graph = graph._replace(nodes=nodes)\n",
        "  return out_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DhG3r8P-aiBb"
      },
      "outputs": [],
      "source": [
        "graph = build_toy_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRHJ_CYthY8P"
      },
      "source": [
        "Here is the visualized graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BsaiSIZYbPzw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "daaac8c9-d8be-4563-b743-099565f7b89d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "draw_jraph_graph_structure(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1zAwAgy2bB1P"
      },
      "outputs": [],
      "source": [
        "out_graph = apply_simplified_gcn(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SwEtzddrbHri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868821cf-7b35-46fa-bf68-5a62a2165544"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[10.],\n",
              "             [ 0.],\n",
              "             [ 2.],\n",
              "             [ 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "out_graph.nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rt3AB2tvv1o"
      },
      "source": [
        "### Add Trainable Parameters to GCN layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cK9W9J4GsDbC"
      },
      "outputs": [],
      "source": [
        "class MLP(hk.Module):\n",
        "  def __init__(self, features: jnp.ndarray):\n",
        "    super().__init__()\n",
        "    self.features = features\n",
        "\n",
        "  def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
        "    layers = []\n",
        "    for feat in self.features[:-1]:\n",
        "      layers.append(hk.Linear(feat))\n",
        "      layers.append(jax.nn.relu)\n",
        "    layers.append(hk.Linear(self.features[-1]))\n",
        "\n",
        "    mlp = hk.Sequential(layers)\n",
        "    return mlp(x)\n",
        "\n",
        "# Use MLP block to define the update node function\n",
        "update_node_fn = lambda x: MLP(features=[8, 4])(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rQCaukgyOue"
      },
      "source": [
        "#### Check outputs of `update_node_fn` with MLP Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_ImWUoi9s2-x"
      },
      "outputs": [],
      "source": [
        "graph = build_toy_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4BCg7cYwyBRw"
      },
      "outputs": [],
      "source": [
        "update_node_module = hk.without_apply_rng(hk.transform(update_node_fn))\n",
        "params = update_node_module.init(jax.random.PRNGKey(42), graph.nodes)\n",
        "out = update_node_module.apply(params, graph.nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PblLCX67ubZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3c20e5-0002-49e0-b37f-c96a43bacf28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "             [-0.14526577,  0.33038154, -0.50791115, -0.64371586],\n",
              "             [-0.29053155,  0.6607631 , -1.0158223 , -1.2874317 ],\n",
              "             [-0.43579727,  0.99114466, -1.5237335 , -1.9311478 ]],            dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD1Qc7xK-SkI"
      },
      "source": [
        "## Add Self-Edges (Edges connecting a node to itself)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "a8LO_UMN-ReR"
      },
      "outputs": [],
      "source": [
        "def add_self_edges_fn(receivers: jnp.ndarray, senders: jnp.ndarray,\n",
        "                      total_num_nodes: int) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
        "  \"\"\"Adds self edges. Assumes self edges are not in the graph yet.\"\"\"\n",
        "  receivers = jnp.concatenate((receivers, jnp.arange(total_num_nodes)), axis=0)\n",
        "  senders = jnp.concatenate((senders, jnp.arange(total_num_nodes)), axis=0)\n",
        "  return receivers, senders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdxzqrpbj-jZ"
      },
      "source": [
        "## General GCN Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KkkOolOVh3nR"
      },
      "outputs": [],
      "source": [
        "\n",
        "def GraphConvolution(update_node_fn: Callable,\n",
        "                     aggregate_nodes_fn: Callable = jax.ops.segment_sum,\n",
        "                     add_self_edges: bool = False,\n",
        "                     symmetric_normalization: bool = True) -> Callable:\n",
        "  \n",
        "\n",
        "  def _ApplyGCN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "    \"\"\"Applies a Graph Convolution layer.\"\"\"\n",
        "    nodes, _, receivers, senders, _, _, _ = graph\n",
        "\n",
        "    # First pass nodes through the node updater.\n",
        "    nodes = update_node_fn(nodes)\n",
        "    # Equivalent to jnp.sum(n_node), but jittable\n",
        "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
        "    if add_self_edges:\n",
        "      # We add self edges to the senders and receivers so that each node\n",
        "      # includes itself in aggregation.\n",
        "      # In principle, a `GraphsTuple` should partition by n_edge, but in\n",
        "      # this case it is not required since a GCN is agnostic to whether\n",
        "      # the `GraphsTuple` is a batch of graphs or a single large graph.\n",
        "      conv_receivers, conv_senders = add_self_edges_fn(receivers, senders,\n",
        "                                                       total_num_nodes)\n",
        "    else:\n",
        "      conv_senders = senders\n",
        "      conv_receivers = receivers\n",
        "\n",
        "    # pylint: disable=g-long-lambda\n",
        "    if symmetric_normalization:\n",
        "      # Calculate the normalization values.\n",
        "      count_edges = lambda x: jax.ops.segment_sum(\n",
        "          jnp.ones_like(conv_senders), x, total_num_nodes)\n",
        "      sender_degree = count_edges(conv_senders)\n",
        "      receiver_degree = count_edges(conv_receivers)\n",
        "\n",
        "      # Pre normalize by sqrt sender degree.\n",
        "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
        "      nodes = tree.tree_map(\n",
        "          lambda x: x * jax.lax.rsqrt(jnp.maximum(sender_degree, 1.0))[:, None],\n",
        "          nodes,\n",
        "      )\n",
        "      # Aggregate the pre-normalized nodes.\n",
        "      nodes = tree.tree_map(\n",
        "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
        "                                       total_num_nodes), nodes)\n",
        "      # Post normalize by sqrt receiver degree.\n",
        "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
        "      nodes = tree.tree_map(\n",
        "          lambda x:\n",
        "          (x * jax.lax.rsqrt(jnp.maximum(receiver_degree, 1.0))[:, None]),\n",
        "          nodes,\n",
        "      )\n",
        "    else:\n",
        "      nodes = tree.tree_map(\n",
        "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
        "                                       total_num_nodes), nodes)\n",
        "    # pylint: enable=g-long-lambda\n",
        "    return graph._replace(nodes=nodes)\n",
        "\n",
        "  return _ApplyGCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKxcA6XAza33"
      },
      "source": [
        "#### Test General GCN Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7TgyCkE9KlUG"
      },
      "outputs": [],
      "source": [
        "gcn_layer = GraphConvolution(\n",
        "    update_node_fn=lambda n: MLP(features=[8, 4])(n),\n",
        "    aggregate_nodes_fn=jax.ops.segment_sum,\n",
        "    add_self_edges=True,\n",
        "    symmetric_normalization=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1gTPEWvU0DDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42916ed-2ee9-443a-c1f8-f7c1330cbec5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[-0.29652247,  0.6743885 , -1.0367693 , -1.3139795 ],\n",
              "             [-0.07263289,  0.16519077, -0.25395554, -0.32185793],\n",
              "             [-0.21789865,  0.4955723 , -0.7618666 , -0.9655737 ],\n",
              "             [-0.21789864,  0.49557233, -0.76186675, -0.9655739 ]],            dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "graph = build_toy_graph()\n",
        "network = hk.without_apply_rng(hk.transform(gcn_layer))\n",
        "params = network.init(jax.random.PRNGKey(42), graph)\n",
        "out_graph = network.apply(params, graph)\n",
        "out_graph.nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lha8rbQ78l3S"
      },
      "source": [
        "## Build GCN Model with Multiple Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QYOQBh848k2U"
      },
      "outputs": [],
      "source": [
        "def gcn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "  \"\"\"Defines a graph neural network with 3 GCN layers.\n",
        "  Args:\n",
        "    graph: GraphsTuple the network processes.\n",
        "\n",
        "  Returns:\n",
        "    output graph with updated node values.\n",
        "  \"\"\"\n",
        "  gn = GraphConvolution(\n",
        "      update_node_fn=lambda n: jax.nn.relu(hk.Linear(8)(n)),\n",
        "      add_self_edges=True)\n",
        "  graph = gn(graph)\n",
        "\n",
        "  gn = GraphConvolution(\n",
        "      update_node_fn=lambda n: jax.nn.relu(hk.Linear(4)(n)),\n",
        "      add_self_edges=True)\n",
        "  graph = gn(graph)\n",
        "\n",
        "  gn = GraphConvolution(\n",
        "      update_node_fn=hk.Linear(2))\n",
        "  graph = gn(graph)\n",
        "  return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "j6CisEhz_A-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f86973-f4d4-4c54-a3b2-a7c3c10da4f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[-0.32386127,  0.10707338],\n",
              "             [-0.23884146,  0.07896456],\n",
              "             [-0.19206828,  0.06350064],\n",
              "             [-0.23884146,  0.07896456]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "graph = build_toy_graph()\n",
        "network = hk.without_apply_rng(hk.transform(gcn))\n",
        "params = network.init(jax.random.PRNGKey(42), graph)\n",
        "out_graph = network.apply(params, graph)\n",
        "out_graph.nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg8g96NdBCK6"
      },
      "source": [
        "## Graph Attention (GAT) Layer\n",
        "\n",
        "While the GCN we covered in the previous section can learn meaningful representations, it also has some shortcomings. Can you think of any?\n",
        "\n",
        "In the GCN layer, the messages from all its neighbours and the node itself are equally weighted. This may lead to loss of node-specific information. E.g., consider the case when a set of nodes shares the same set of neighbors, and start out with different node features. Then because of averaging, their resulting output features would be the same. Adding self-edges mitigates this issue by a small amount, but this problem is magnified with increasing number of GCN layers and number of edges connecting to a node.\n",
        "\n",
        "The graph attention (GAT) mechanism, as proposed by [Velickovic et al. ( 2017)](https://arxiv.org/abs/1710.10903), allows the network to learn how to weigh / assign importance to the node features from the neighbourhood when computing the new node features. This is very similar to the idea of using attention in Transformers, which were introduced in [Vaswani et al. (2017)](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "(One could even argue that Transformers are graph attention networks operating on the special case of fully-connected graphs.)\n",
        "\n",
        "In the figure below, $\\vec{h}$ are the node features and $\\vec{\\alpha}$ are the learned attention weights.\n",
        "\n",
        "\n",
        "\n",
        "<image src=\"https://storage.googleapis.com/dm-educational/assets/graph-nets/gat1.png\" width=\"400px\">\n",
        "\n",
        "Figure Credit: [Velickovic et al. ( 2017)](https://arxiv.org/abs/1710.10903).\n",
        "(Detail: This image is showing multi-headed attention with 3 heads, each color corresponding to a different head. At the end, an aggregation function is applied over all the heads.)\n",
        "\n",
        "To obtain the output node features of the GAT layer, we compute:\n",
        "\n",
        "$$ \\vec{h}'_i = \\sum _{j \\in \\mathcal{N}(i)}\\alpha_{ij} \\mathbf{W} \\vec{h}_j$$\n",
        "Here, $\\mathbf{W}$ is a weight matrix which performs a linear transformation on the input.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qa6dOLBGLlP"
      },
      "source": [
        "\n",
        "How do we obtain $\\alpha$, or in other words, learn what to pay attention to?\n",
        "\n",
        "Intuitively, the attention coefficient $\\alpha_{ij}$ should rely on both the transformed features from nodes $i$ and $j$. So let's first define an attention mechanism function $\\mathrm{attention\\_fn}$ that computes the intermediary attention coefficients $e_{ij}$:\n",
        "$$ e_{ij} = \\mathrm{attention\\_fn}(\\mathbf{W}\\vec{h}_i, \\mathbf{W}\\vec{h}_j)$$\n",
        "\n",
        "To obtain normalized attention weights $\\alpha$, we apply a softmax:\n",
        "$$\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum _{j \\in \\mathcal{N}(i)}\\exp(e_{ij})}$$\n",
        "\n",
        "For the function $a$, the authors of the GAT paper chose to concatenate the transformed node features (denoted by $||$) and apply a single-layer feedforward network, parameterized by a weight vector $\\vec{\\mathbf{a}}$ and with LeakyRelu as non-linearity.\n",
        "\n",
        "In the implementation below, we refer to $\\mathbf{W}$ as `attention_query_fn` and $att\\_fn$ as `attention_logit_fn`.\n",
        "\n",
        "$$\\mathrm{attention\\_fn}(\\mathbf{W}\\vec{h}_i, \\mathbf{W}\\vec{h}_j) =  \\text{LeakyReLU}(\\vec{\\mathbf{a}}(\\mathbf{W}\\vec{h}_i || \\mathbf{W}\\vec{h}_j))$$\n",
        "\n",
        "The figure below summarizes this attention mechanism visually.\n",
        "\n",
        "<image src=\"https://storage.googleapis.com/dm-educational/assets/graph-nets/gat2.png\" width=\"300px\">\n",
        "\n",
        "Figure Credit: Petar Velickovic.\n",
        "<!-- $\\sum_{j \\in \\mathcal{N}(i)}\\vec{\\alpha}_{ij} \\stackrel{!}{=}\n",
        "1 $  -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJqT6mjgBBmQ"
      },
      "outputs": [],
      "source": [
        "# GAT implementation adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L442.\n",
        "def GAT(attention_query_fn: Callable,\n",
        "        attention_logit_fn: Callable,\n",
        "        node_update_fn: Optional[Callable] = None,\n",
        "        add_self_edges: bool = True) -> Callable:\n",
        "  \"\"\"Returns a method that applies a Graph Attention Network layer.\n",
        "\n",
        "  Graph Attention message passing as described in\n",
        "  https://arxiv.org/pdf/1710.10903.pdf. This model expects node features as a\n",
        "  jnp.array, may use edge features for computing attention weights, and\n",
        "  ignore global features. It does not support nests.\n",
        "  Args:\n",
        "    attention_query_fn: function that generates attention queries from sender\n",
        "      node features.\n",
        "    attention_logit_fn: function that converts attention queries into logits for\n",
        "      softmax attention.\n",
        "    node_update_fn: function that updates the aggregated messages. If None, will\n",
        "      apply leaky relu and concatenate (if using multi-head attention).\n",
        "\n",
        "  Returns:\n",
        "    A function that applies a Graph Attention layer.\n",
        "  \"\"\"\n",
        "  # pylint: disable=g-long-lambda\n",
        "  if node_update_fn is None:\n",
        "    # By default, apply the leaky relu and then concatenate the heads on the\n",
        "    # feature axis.\n",
        "    node_update_fn = lambda x: jnp.reshape(\n",
        "        jax.nn.leaky_relu(x), (x.shape[0], -1))\n",
        "\n",
        "  def _ApplyGAT(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "    \"\"\"Applies a Graph Attention layer.\"\"\"\n",
        "    nodes, edges, receivers, senders, _, _, _ = graph\n",
        "    # Equivalent to the sum of n_node, but statically known.\n",
        "    try:\n",
        "      sum_n_node = nodes.shape[0]\n",
        "    except IndexError:\n",
        "      raise IndexError('GAT requires node features')\n",
        "\n",
        "    # Pass nodes through the attention query function to transform\n",
        "    # node features, e.g. with an MLP.\n",
        "    nodes = attention_query_fn(nodes)\n",
        "\n",
        "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
        "    if add_self_edges:\n",
        "      # We add self edges to the senders and receivers so that each node\n",
        "      # includes itself in aggregation.\n",
        "      receivers, senders = add_self_edges_fn(receivers, senders,\n",
        "                                             total_num_nodes)\n",
        "\n",
        "    # We compute the softmax logits using a function that takes the\n",
        "    # embedded sender and receiver attributes.\n",
        "    sent_attributes = nodes[senders]\n",
        "    received_attributes = nodes[receivers]\n",
        "    att_softmax_logits = attention_logit_fn(sent_attributes,\n",
        "                                            received_attributes, edges)\n",
        "\n",
        "    # Compute the attention softmax weights on the entire tree.\n",
        "    att_weights = jraph.segment_softmax(\n",
        "        att_softmax_logits, segment_ids=receivers, num_segments=sum_n_node)\n",
        "\n",
        "    # Apply attention weights.\n",
        "    messages = sent_attributes * att_weights\n",
        "    # Aggregate messages to nodes.\n",
        "    nodes = jax.ops.segment_sum(messages, receivers, num_segments=sum_n_node)\n",
        "\n",
        "    # Apply an update function to the aggregated messages.\n",
        "    nodes = node_update_fn(nodes)\n",
        "\n",
        "    return graph._replace(nodes=nodes)\n",
        "\n",
        "  # pylint: enable=g-long-lambda\n",
        "  return _ApplyGAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t9bNfSA9-HR"
      },
      "source": [
        "#### Test GAT Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjpYLFvv9-HT"
      },
      "outputs": [],
      "source": [
        "def attention_logit_fn(sender_attr: jnp.ndarray, receiver_attr: jnp.ndarray,\n",
        "                       edges: jnp.ndarray) -> jnp.ndarray:\n",
        "  del edges\n",
        "  x = jnp.concatenate((sender_attr, receiver_attr), axis=1)\n",
        "  return hk.Linear(1)(x)\n",
        "\n",
        "\n",
        "gat_layer = GAT(\n",
        "    attention_query_fn=lambda n: hk.Linear(8)\n",
        "    (n),  # Applies W to the node features\n",
        "    attention_logit_fn=attention_logit_fn,\n",
        "    node_update_fn=None,\n",
        "    add_self_edges=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV5PndNz9-HT"
      },
      "outputs": [],
      "source": [
        "graph = build_toy_graph()\n",
        "network = hk.without_apply_rng(hk.transform(gat_layer))\n",
        "params = network.init(jax.random.PRNGKey(42), graph)\n",
        "out_graph = network.apply(params, graph)\n",
        "out_graph.nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anfVGJwBe27v"
      },
      "source": [
        "### Train GAT Model on Karate Club Dataset\n",
        "We will now repeat the karate club experiment with a GAT network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUXJcRnVMr4X"
      },
      "outputs": [],
      "source": [
        "def gat_definition(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "  \"\"\"Defines a GAT network for the karate club node classification task.\n",
        "\n",
        "  Args:\n",
        "    graph: GraphsTuple the network processes.\n",
        "\n",
        "  Returns:\n",
        "    output graph with updated node values.\n",
        "  \"\"\"\n",
        "\n",
        "  def _attention_logit_fn(sender_attr: jnp.ndarray, receiver_attr: jnp.ndarray,\n",
        "                          edges: jnp.ndarray) -> jnp.ndarray:\n",
        "    del edges\n",
        "    x = jnp.concatenate((sender_attr, receiver_attr), axis=1)\n",
        "    return hk.Linear(1)(x)\n",
        "\n",
        "  gn = GAT(\n",
        "      attention_query_fn=lambda n: hk.Linear(8)(n),\n",
        "      attention_logit_fn=_attention_logit_fn,\n",
        "      node_update_fn=None,\n",
        "      add_self_edges=True)\n",
        "  graph = gn(graph)\n",
        "\n",
        "  gn = GAT(\n",
        "      attention_query_fn=lambda n: hk.Linear(8)(n),\n",
        "      attention_logit_fn=_attention_logit_fn,\n",
        "      node_update_fn=hk.Linear(2),\n",
        "      add_self_edges=True)\n",
        "  graph = gn(graph)\n",
        "  return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51AwRipThKrH"
      },
      "source": [
        "Let's train the model!\n",
        "\n",
        "We expect the model to reach an accuracy of about 0.97."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEHco8n-Mr4b"
      },
      "outputs": [],
      "source": [
        "network = hk.without_apply_rng(hk.transform(gat_definition))\n",
        "result = optimize_club(network, num_steps=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7Cns9EITp0k"
      },
      "source": [
        "The final node assignment predicted by the trained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QWqU8AfdkkV"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0leRi5igUUyd"
      },
      "outputs": [],
      "source": [
        "zacharys_karate_club = get_zacharys_karate_club()\n",
        "nx_graph = convert_jraph_to_networkx_graph(zacharys_karate_club)\n",
        "pos = nx.circular_layout(nx_graph)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "ax1 = fig.add_subplot(121)\n",
        "nx.draw(\n",
        "    nx_graph,\n",
        "    pos=pos,\n",
        "    with_labels=True,\n",
        "    node_size=500,\n",
        "    node_color=result.tolist(),\n",
        "    font_color='white')\n",
        "ax1.title.set_text('Predicted Node Assignments with GAT')\n",
        "\n",
        "gt_labels = get_ground_truth_assignments_for_zacharys_karate_club()\n",
        "ax2 = fig.add_subplot(122)\n",
        "nx.draw(\n",
        "    nx_graph,\n",
        "    pos=pos,\n",
        "    with_labels=True,\n",
        "    node_size=500,\n",
        "    node_color=gt_labels.tolist(),\n",
        "    font_color='white')\n",
        "ax2.title.set_text('Ground-Truth Node Assignments')\n",
        "fig.suptitle('Do you spot the difference? 😐', y=-0.01)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwVE88dTRC6V"
      },
      "source": [
        "## Edge prediction on CORA (Citation Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6Qo4jSfHtdQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f13d3a-ef25-46d8-af37-74815bb2dd9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-18 01:15:57--  https://storage.googleapis.com/dm-educational/assets/graph-nets/jraph_datasets/cora.pickle\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 172.253.123.128, 142.250.98.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15618018 (15M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cora.pickle’\n",
            "\n",
            "cora.pickle         100%[===================>]  14.89M  79.8MB/s    in 0.2s    \n",
            "\n",
            "2022-05-18 01:15:58 (79.8 MB/s) - ‘/tmp/cora.pickle’ saved [15618018/15618018]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download jraph version of Cora.\n",
        "!wget -P /tmp/ https://storage.googleapis.com/dm-educational/assets/graph-nets/jraph_datasets/cora.pickle\n",
        "with open('/tmp/cora.pickle', 'rb') as f:\n",
        "  cora_ds = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lc0O4_h9Bfv"
      },
      "source": [
        "## Splitting Edges and Adding \"Negative\" Edges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iqZyzwpC3p-u"
      },
      "outputs": [],
      "source": [
        "def train_val_test_split_edges(graph: jraph.GraphsTuple,\n",
        "                               val_perc: float = 0.05,\n",
        "                               test_perc: float = 0.1):\n",
        "  \"\"\"Split edges in input graph into train, val and test splits.\n",
        "\n",
        "  For val and test sets, also include negative edges.\n",
        "  Based on torch_geometric.utils.train_test_split_edges.\n",
        "  \"\"\"\n",
        "  mask = graph.senders < graph.receivers\n",
        "  senders = graph.senders[mask]\n",
        "  receivers = graph.receivers[mask]\n",
        "  num_val = int(val_perc * senders.shape[0])\n",
        "  num_test = int(test_perc * senders.shape[0])\n",
        "  permuted_indices = onp.random.permutation(range(senders.shape[0]))\n",
        "  senders = senders[permuted_indices]\n",
        "  receivers = receivers[permuted_indices]\n",
        "  if graph.edges is not None:\n",
        "    edges = graph.edges[permuted_indices]\n",
        "\n",
        "  val_senders = senders[:num_val]\n",
        "  val_receivers = receivers[:num_val]\n",
        "  if graph.edges is not None:\n",
        "    val_edges = edges[:num_val]\n",
        "\n",
        "  test_senders = senders[num_val:num_val + num_test]\n",
        "  test_receivers = receivers[num_val:num_val + num_test]\n",
        "  if graph.edges is not None:\n",
        "    test_edges = edges[num_val:num_val + num_test]\n",
        "\n",
        "  train_senders = senders[num_val + num_test:]\n",
        "  train_receivers = receivers[num_val + num_test:]\n",
        "  train_edges = None\n",
        "  if graph.edges is not None:\n",
        "    train_edges = edges[num_val + num_test:]\n",
        "\n",
        "  # make training edges undirected by adding reverse edges back in\n",
        "  train_senders_undir = jnp.concatenate((train_senders, train_receivers))\n",
        "  train_receivers_undir = jnp.concatenate((train_receivers, train_senders))\n",
        "  train_senders = train_senders_undir\n",
        "  train_receivers = train_receivers_undir\n",
        "\n",
        "  # Negative edges.\n",
        "  num_nodes = graph.n_node[0]\n",
        "  # Create a negative adjacency mask, s.t. mask[i, j] = True iff edge i->j does\n",
        "  # not exist in the original graph.\n",
        "  neg_adj_mask = onp.ones((num_nodes, num_nodes), dtype=onp.uint8)\n",
        "  # upper triangular part\n",
        "  neg_adj_mask = onp.triu(neg_adj_mask, k=1)\n",
        "  neg_adj_mask[graph.senders, graph.receivers] = 0\n",
        "  neg_adj_mask = neg_adj_mask.astype(onp.bool)\n",
        "  neg_senders, neg_receivers = neg_adj_mask.nonzero()\n",
        "\n",
        "  perm = onp.random.permutation(range(len(neg_senders)))\n",
        "  neg_senders = neg_senders[perm]\n",
        "  neg_receivers = neg_receivers[perm]\n",
        "\n",
        "  val_neg_senders = neg_senders[:num_val]\n",
        "  val_neg_receivers = neg_receivers[:num_val]\n",
        "  test_neg_senders = neg_senders[num_val:num_val + num_test]\n",
        "  test_neg_receivers = neg_receivers[num_val:num_val + num_test]\n",
        "\n",
        "  train_graph = jraph.GraphsTuple(\n",
        "      nodes=graph.nodes,\n",
        "      edges=train_edges,\n",
        "      senders=train_senders,\n",
        "      receivers=train_receivers,\n",
        "      n_node=graph.n_node,\n",
        "      n_edge=jnp.array([len(train_senders)]),\n",
        "      globals=graph.globals)\n",
        "\n",
        "  return train_graph, neg_adj_mask, val_senders, val_receivers, val_neg_senders, val_neg_receivers, test_senders, test_receivers, test_neg_senders, test_neg_receivers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cE2CNtN-G3D"
      },
      "source": [
        "## Test the Edge Splitting Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LhBruorYJPm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9032be-e954-40a7-fc48-9e287c57a9f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "graph = cora_ds[0]['input_graph']\n",
        "train_graph, neg_adj_mask, val_pos_senders, val_pos_receivers, val_neg_senders, val_neg_receivers, test_pos_senders, test_pos_receivers, test_neg_senders, test_neg_receivers = train_val_test_split_edges(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sOMs84n4Gz1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a76e93-b619-406a-8a5d-220a62213d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 8976 positive edges, we will sample the same number of negative edges at runtime\n",
            "Val set: 263 positive edges, 263 negative edges\n",
            "Test set: 527 positive edges, 527 negative edges\n",
            "Negative adjacency mask shape: (2708, 2708)\n",
            "Numbe of negative edges to sample from: 3660000\n"
          ]
        }
      ],
      "source": [
        "print(f'Train set: {train_graph.senders.shape[0]} positive edges, we will sample the same number of negative edges at runtime')\n",
        "print(f'Val set: {val_pos_senders.shape[0]} positive edges, {val_neg_senders.shape[0]} negative edges')\n",
        "print(f'Test set: {test_pos_senders.shape[0]} positive edges, {test_neg_senders.shape[0]} negative edges')\n",
        "print(f'Negative adjacency mask shape: {neg_adj_mask.shape}')\n",
        "print(f'Numbe of negative edges to sample from: {neg_adj_mask.sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaGRJAyfLwed"
      },
      "source": [
        "## Graph Network Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "sC3AMCrJLwek"
      },
      "outputs": [],
      "source": [
        "@jraph.concatenated_args\n",
        "def node_update_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Node update function for graph net.\"\"\"\n",
        "  net = hk.Sequential([hk.Linear(128), jax.nn.relu, hk.Linear(64)])\n",
        "  return net(feats)\n",
        "\n",
        "\n",
        "def net_fn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "  \"\"\"Network definition.\"\"\"\n",
        "  graph = graph._replace(globals=jnp.zeros([graph.n_node.shape[0], 1]))\n",
        "  net = jraph.GraphNetwork(\n",
        "      update_node_fn=node_update_fn, update_edge_fn=None, update_global_fn=None)\n",
        "  return net(graph)\n",
        "\n",
        "\n",
        "def decode(pred_graph: jraph.GraphsTuple, senders: jnp.ndarray,\n",
        "           receivers: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Given a set of candidate edges, take dot product of respective nodes.\n",
        "\n",
        "  Args:\n",
        "    pred_graph: input graph.\n",
        "    senders: Senders of candidate edges.\n",
        "    receivers: Receivers of candidate edges.\n",
        "\n",
        "  Returns:\n",
        "    For each edge, computes dot product of the features of the two nodes.\n",
        "\n",
        "  \"\"\"\n",
        "  return jnp.squeeze(\n",
        "      jnp.sum(pred_graph.nodes[senders] * pred_graph.nodes[receivers], axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGz7iRGmLwel"
      },
      "source": [
        "## Loss and ROC-AUC-Metric Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_Ld4b3D6Lwel"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_bce_with_logits_loss(x: jnp.ndarray, y: jnp.ndarray) -> jnp.ndarray:\n",
        "  max_val = jnp.clip(x, 0, None)\n",
        "  loss = x - x * y + max_val + jnp.log(\n",
        "      jnp.exp(-max_val) + jnp.exp((-x - max_val)))\n",
        "  return loss.mean()\n",
        "\n",
        "\n",
        "def compute_loss(params: hk.Params, graph: jraph.GraphsTuple,\n",
        "                 senders: jnp.ndarray, receivers: jnp.ndarray,\n",
        "                 labels: jnp.ndarray,\n",
        "                 net: hk.Transformed) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
        "  \"\"\"Computes loss.\"\"\"\n",
        "  pred_graph = net.apply(params, graph)\n",
        "  preds = decode(pred_graph, senders, receivers)\n",
        "  loss = compute_bce_with_logits_loss(preds, labels)\n",
        "  return loss, preds\n",
        "\n",
        "\n",
        "def compute_roc_auc_score(preds: jnp.ndarray,\n",
        "                          labels: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Computes roc auc (area under the curve) score for classification.\"\"\"\n",
        "  s = jax.nn.sigmoid(preds)\n",
        "  roc_auc = roc_auc_score(labels, s)\n",
        "  return roc_auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58D3mm9blJFD"
      },
      "source": [
        "Helper function for sampling negative edges during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "gTZ4CwVDWrc9"
      },
      "outputs": [],
      "source": [
        "def negative_sampling(\n",
        "    graph: jraph.GraphsTuple, num_neg_samples: int,\n",
        "    key: jnp.DeviceArray) -> Tuple[jnp.DeviceArray, jnp.DeviceArray]:\n",
        "  \"\"\"Samples negative edges, i.e. edges that don't exist in the input graph.\"\"\"\n",
        "  num_nodes = graph.n_node[0]\n",
        "  total_possible_edges = num_nodes**2\n",
        "  # convert 2D edge indices to 1D representation.\n",
        "  pos_idx = graph.senders * num_nodes + graph.receivers\n",
        "\n",
        "  # Percentage to oversample edges, so most likely will sample enough neg edges.\n",
        "  alpha = jnp.abs(1 / (1 - 1.1 *\n",
        "                       (graph.senders.shape[0] / total_possible_edges)))\n",
        "\n",
        "  perm = jax.random.randint(\n",
        "      key,\n",
        "      shape=(int(alpha * num_neg_samples),),\n",
        "      minval=0,\n",
        "      maxval=total_possible_edges,\n",
        "      dtype=jnp.uint32)\n",
        "\n",
        "  # mask where sampled edges are positive edges.\n",
        "  mask = jnp.isin(perm, pos_idx)\n",
        "  # remove positive edges.\n",
        "  perm = perm[~mask][:num_neg_samples]\n",
        "\n",
        "  # convert 1d back to 2d edge indices.\n",
        "  neg_senders = perm // num_nodes\n",
        "  neg_receivers = perm % num_nodes\n",
        "\n",
        "  return neg_senders, neg_receivers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5xUW5XkL3YS"
      },
      "source": [
        "Let's write the training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "xAjfWFduSESI"
      },
      "outputs": [],
      "source": [
        "def train(dataset: List[Dict[str, Any]], num_epochs: int) -> hk.Params:\n",
        "  \"\"\"Training loop.\"\"\"\n",
        "  key = jax.random.PRNGKey(42)\n",
        "  # Transform impure `net_fn` to pure functions with hk.transform.\n",
        "  net = hk.without_apply_rng(hk.transform(net_fn))\n",
        "  # Get a candidate graph and label to initialize the network.\n",
        "  graph = dataset[0]['input_graph']\n",
        "\n",
        "  train_graph, _, val_pos_s, val_pos_r, val_neg_s, val_neg_r, test_pos_s, \\\n",
        "      test_pos_r, test_neg_s, test_neg_r = train_val_test_split_edges(\n",
        "      graph)\n",
        "\n",
        "  # Prepare the validation and test data.\n",
        "  val_senders = jnp.concatenate((val_pos_s, val_neg_s))\n",
        "  val_receivers = jnp.concatenate((val_pos_r, val_neg_r))\n",
        "  val_labels = jnp.concatenate(\n",
        "      (jnp.ones(len(val_pos_s)), jnp.zeros(len(val_neg_s))))\n",
        "  test_senders = jnp.concatenate((test_pos_s, test_neg_s))\n",
        "  test_receivers = jnp.concatenate((test_pos_r, test_neg_r))\n",
        "  test_labels = jnp.concatenate(\n",
        "      (jnp.ones(len(test_pos_s)), jnp.zeros(len(test_neg_s))))\n",
        "  # Initialize the network.\n",
        "  params = net.init(key, train_graph)\n",
        "  # Initialize the optimizer.\n",
        "  opt_init, opt_update = optax.adam(1e-4)\n",
        "  opt_state = opt_init(params)\n",
        "\n",
        "  compute_loss_fn = functools.partial(compute_loss, net=net)\n",
        "  # We jit the computation of our loss, since this is the main computation.\n",
        "  # Using jax.jit means that we will use a single accelerator. If you want\n",
        "  # to use more than 1 accelerator, use jax.pmap. More information can be\n",
        "  # found in the jax documentation.\n",
        "  compute_loss_fn = jax.jit(jax.value_and_grad(compute_loss_fn, has_aux=True))\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    num_neg_samples = train_graph.senders.shape[0]\n",
        "    train_neg_senders, train_neg_receivers = negative_sampling(\n",
        "        train_graph, num_neg_samples=num_neg_samples, key=key)\n",
        "    train_senders = jnp.concatenate((train_graph.senders, train_neg_senders))\n",
        "    train_receivers = jnp.concatenate(\n",
        "        (train_graph.receivers, train_neg_receivers))\n",
        "    train_labels = jnp.concatenate(\n",
        "        (jnp.ones(len(train_graph.senders)), jnp.zeros(len(train_neg_senders))))\n",
        "\n",
        "    (train_loss,\n",
        "     train_preds), grad = compute_loss_fn(params, train_graph, train_senders,\n",
        "                                          train_receivers, train_labels)\n",
        "\n",
        "    updates, opt_state = opt_update(grad, opt_state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    if epoch % 10 == 0 or epoch == (num_epochs - 1):\n",
        "      train_roc_auc = compute_roc_auc_score(train_preds, train_labels)\n",
        "      val_loss, val_preds = compute_loss(params, train_graph, val_senders,\n",
        "                                         val_receivers, val_labels, net)\n",
        "      val_roc_auc = compute_roc_auc_score(val_preds, val_labels)\n",
        "      print(f'epoch: {epoch}, train_loss: {train_loss:.3f}, '\n",
        "            f'train_roc_auc: {train_roc_auc:.3f}, val_loss: {val_loss:.3f}, '\n",
        "            f'val_roc_auc: {val_roc_auc:.3f}')\n",
        "  test_loss, test_preds = compute_loss(params, train_graph, test_senders,\n",
        "                                       test_receivers, test_labels, net)\n",
        "  test_roc_auc = compute_roc_auc_score(test_preds, test_labels)\n",
        "  print('Training finished')\n",
        "  print(\n",
        "      f'epoch: {epoch}, test_loss: {test_loss:.3f}, test_roc_auc: {test_roc_auc:.3f}'\n",
        "  )\n",
        "  return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8LJtk4WKenoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747f60ea-9d79-433e-b1c6-27bc3aae4e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, train_loss: 0.690, train_roc_auc: 0.598, val_loss: 0.689, val_roc_auc: 0.639\n",
            "epoch: 10, train_loss: 0.686, train_roc_auc: 0.699, val_loss: 0.686, val_roc_auc: 0.691\n",
            "epoch: 20, train_loss: 0.680, train_roc_auc: 0.760, val_loss: 0.682, val_roc_auc: 0.720\n",
            "epoch: 30, train_loss: 0.673, train_roc_auc: 0.791, val_loss: 0.678, val_roc_auc: 0.736\n",
            "epoch: 40, train_loss: 0.664, train_roc_auc: 0.813, val_loss: 0.672, val_roc_auc: 0.751\n",
            "epoch: 50, train_loss: 0.651, train_roc_auc: 0.835, val_loss: 0.663, val_roc_auc: 0.767\n",
            "epoch: 60, train_loss: 0.636, train_roc_auc: 0.855, val_loss: 0.652, val_roc_auc: 0.784\n",
            "epoch: 70, train_loss: 0.617, train_roc_auc: 0.871, val_loss: 0.639, val_roc_auc: 0.799\n",
            "epoch: 80, train_loss: 0.595, train_roc_auc: 0.883, val_loss: 0.623, val_roc_auc: 0.811\n",
            "epoch: 90, train_loss: 0.571, train_roc_auc: 0.890, val_loss: 0.606, val_roc_auc: 0.819\n",
            "epoch: 100, train_loss: 0.546, train_roc_auc: 0.895, val_loss: 0.590, val_roc_auc: 0.824\n",
            "epoch: 110, train_loss: 0.523, train_roc_auc: 0.901, val_loss: 0.577, val_roc_auc: 0.828\n",
            "epoch: 120, train_loss: 0.501, train_roc_auc: 0.909, val_loss: 0.569, val_roc_auc: 0.833\n",
            "epoch: 130, train_loss: 0.482, train_roc_auc: 0.918, val_loss: 0.564, val_roc_auc: 0.836\n",
            "epoch: 140, train_loss: 0.464, train_roc_auc: 0.928, val_loss: 0.561, val_roc_auc: 0.839\n",
            "epoch: 150, train_loss: 0.447, train_roc_auc: 0.937, val_loss: 0.560, val_roc_auc: 0.842\n",
            "epoch: 160, train_loss: 0.431, train_roc_auc: 0.944, val_loss: 0.560, val_roc_auc: 0.844\n",
            "epoch: 170, train_loss: 0.415, train_roc_auc: 0.951, val_loss: 0.561, val_roc_auc: 0.846\n",
            "epoch: 180, train_loss: 0.400, train_roc_auc: 0.957, val_loss: 0.563, val_roc_auc: 0.848\n",
            "epoch: 190, train_loss: 0.386, train_roc_auc: 0.963, val_loss: 0.567, val_roc_auc: 0.850\n",
            "epoch: 199, train_loss: 0.373, train_roc_auc: 0.967, val_loss: 0.570, val_roc_auc: 0.849\n",
            "Training finished\n",
            "epoch: 199, test_loss: 0.566, test_roc_auc: 0.834\n"
          ]
        }
      ],
      "source": [
        "params = train(cora_ds, num_epochs=200)"
      ]
    }
  ]
}